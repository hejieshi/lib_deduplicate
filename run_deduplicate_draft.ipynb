{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec80a509",
   "metadata": {},
   "source": [
    "## 最后要把所有的tqdm删掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d5465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类外函数名为addFun格式\n",
    "# 类内函数名及变量为add_fun格式\n",
    "# 类格式AddFun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9de07c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import fuzz\n",
    "import redis\n",
    "r = redis.Redis('localhost', 6379)\n",
    "\n",
    "# 中文标题的hashcode不能全置0，要改\n",
    "from tool import hashString,hashStringOdd,hashStringEven,hashString3,containChinese\n",
    "from H5File import H5File\n",
    "from generate_id import IdWorker\n",
    "worker = IdWorker(1,2)\n",
    "from merge import mergeColumnAndTitle\n",
    "\n",
    "max_bucket_size = 0\n",
    "repeat_count = 0\n",
    "repeat_2 = 0\n",
    "result_list = []\n",
    "\n",
    "columns_list = {}\n",
    "with open('column_config.json','r') as f:\n",
    "    columns_list = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e482be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def main():\n",
    "    h5file = H5File(3, 2021)\n",
    "    h5file.generate_DataFrame()\n",
    "    h5file.add_title_code()\n",
    "    pdata = h5file.pdata\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6baf76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 274 ms, sys: 14.1 ms, total: 288 ms\n",
      "Wall time: 286 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h5file = H5File(8, 2021)\n",
    "h5file.generate_DataFrame()\n",
    "# h5file.add_title_alter()\n",
    "# h5file.add_id_mark()\n",
    "h5file.add_title_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18e115bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14168"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(h5file.pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d28c2e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>provider_subject</th>\n",
       "      <th>source_file</th>\n",
       "      <th>title_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20855735608</td>\n",
       "      <td>广东省财政厅关于做好2020年度国有企业财务会计决算报告工作的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>地方法规规章</td>\n",
       "      <td>111</td>\n",
       "      <td>广东省财政厅关于做好2020年度国有企业财务会计决算报告工作的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20855737066</td>\n",
       "      <td>郑州市商务局、郑州市财政局关于做好河南省跨境电子商务海外仓示范企业申报的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>地方法规规章</td>\n",
       "      <td>111</td>\n",
       "      <td>郑州市商务局郑州市财政局关于做好河南省跨境电子商务海外仓示范企业申报的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20855748866</td>\n",
       "      <td>第十三届全国人民代表大会宪法和法律委员会关于《全国人民代表大会关于修改＜中华人民共和国全国人...</td>\n",
       "      <td>ZH</td>\n",
       "      <td>立法草案</td>\n",
       "      <td>111</td>\n",
       "      <td>第十三届全国人民代表大会宪法和法律委员会关于全国人民代表大会关于修改中华人民共和国全国人民代...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20855749144</td>\n",
       "      <td>生态环境部关于山西兰花科创玉溪煤矿有限责任公司玉溪煤矿新建项目变更环境影响报告书的批复</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>111</td>\n",
       "      <td>生态环境部关于山西兰花科创玉溪煤矿有限责任公司玉溪煤矿新建项目变更环境影响报告书的批复</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20855749595</td>\n",
       "      <td>2021年宁夏回族自治区政府工作报告</td>\n",
       "      <td>ZH</td>\n",
       "      <td></td>\n",
       "      <td>111</td>\n",
       "      <td>2021年宁夏回族自治区政府工作报告</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title language  \\\n",
       "0  20855735608                  广东省财政厅关于做好2020年度国有企业财务会计决算报告工作的通知       ZH   \n",
       "1  20855737066             郑州市商务局、郑州市财政局关于做好河南省跨境电子商务海外仓示范企业申报的通知       ZH   \n",
       "2  20855748866  第十三届全国人民代表大会宪法和法律委员会关于《全国人民代表大会关于修改＜中华人民共和国全国人...       ZH   \n",
       "3  20855749144        生态环境部关于山西兰花科创玉溪煤矿有限责任公司玉溪煤矿新建项目变更环境影响报告书的批复       ZH   \n",
       "4  20855749595                                 2021年宁夏回族自治区政府工作报告       ZH   \n",
       "\n",
       "  provider_subject source_file  \\\n",
       "0           地方法规规章         111   \n",
       "1           地方法规规章         111   \n",
       "2             立法草案         111   \n",
       "3         中央法规司法解释         111   \n",
       "4                          111   \n",
       "\n",
       "                                          title_code  \n",
       "0                  广东省财政厅关于做好2020年度国有企业财务会计决算报告工作的通知  \n",
       "1              郑州市商务局郑州市财政局关于做好河南省跨境电子商务海外仓示范企业申报的通知  \n",
       "2  第十三届全国人民代表大会宪法和法律委员会关于全国人民代表大会关于修改中华人民共和国全国人民代...  \n",
       "3        生态环境部关于山西兰花科创玉溪煤矿有限责任公司玉溪煤矿新建项目变更环境影响报告书的批复  \n",
       "4                                 2021年宁夏回族自治区政府工作报告  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file.pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e691c45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>provider_subject</th>\n",
       "      <th>source_file</th>\n",
       "      <th>title_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>20855805686</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(四期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>945</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息四期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3672</th>\n",
       "      <td>20855806346</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(五期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>729</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息五期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>20855846606</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(九期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>572</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息九期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>20855847040</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(八期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>715</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息八期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>20855805771</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(六期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>870</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息六期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>20855735890</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(一期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>304</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息一期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8881</th>\n",
       "      <td>20855807050</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(二期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>662</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息二期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10648</th>\n",
       "      <td>20855847547</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(七期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>527</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息七期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846</th>\n",
       "      <td>20856179484</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(十期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>456</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息十期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13903</th>\n",
       "      <td>20855748568</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息(三期)国债发行工作有关事宜的通知</td>\n",
       "      <td>ZH</td>\n",
       "      <td>中央法规司法解释</td>\n",
       "      <td>230</td>\n",
       "      <td>财政部办公厅关于2021年记账式附息三期国债发行工作有关事宜的通知</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                                title language  \\\n",
       "2519   20855805686  财政部办公厅关于2021年记账式附息(四期)国债发行工作有关事宜的通知       ZH   \n",
       "3672   20855806346  财政部办公厅关于2021年记账式附息(五期)国债发行工作有关事宜的通知       ZH   \n",
       "3709   20855846606  财政部办公厅关于2021年记账式附息(九期)国债发行工作有关事宜的通知       ZH   \n",
       "7970   20855847040  财政部办公厅关于2021年记账式附息(八期)国债发行工作有关事宜的通知       ZH   \n",
       "8140   20855805771  财政部办公厅关于2021年记账式附息(六期)国债发行工作有关事宜的通知       ZH   \n",
       "8506   20855735890  财政部办公厅关于2021年记账式附息(一期)国债发行工作有关事宜的通知       ZH   \n",
       "8881   20855807050  财政部办公厅关于2021年记账式附息(二期)国债发行工作有关事宜的通知       ZH   \n",
       "10648  20855847547  财政部办公厅关于2021年记账式附息(七期)国债发行工作有关事宜的通知       ZH   \n",
       "12846  20856179484  财政部办公厅关于2021年记账式附息(十期)国债发行工作有关事宜的通知       ZH   \n",
       "13903  20855748568  财政部办公厅关于2021年记账式附息(三期)国债发行工作有关事宜的通知       ZH   \n",
       "\n",
       "      provider_subject source_file                         title_code  \n",
       "2519          中央法规司法解释         945  财政部办公厅关于2021年记账式附息四期国债发行工作有关事宜的通知  \n",
       "3672          中央法规司法解释         729  财政部办公厅关于2021年记账式附息五期国债发行工作有关事宜的通知  \n",
       "3709          中央法规司法解释         572  财政部办公厅关于2021年记账式附息九期国债发行工作有关事宜的通知  \n",
       "7970          中央法规司法解释         715  财政部办公厅关于2021年记账式附息八期国债发行工作有关事宜的通知  \n",
       "8140          中央法规司法解释         870  财政部办公厅关于2021年记账式附息六期国债发行工作有关事宜的通知  \n",
       "8506          中央法规司法解释         304  财政部办公厅关于2021年记账式附息一期国债发行工作有关事宜的通知  \n",
       "8881          中央法规司法解释         662  财政部办公厅关于2021年记账式附息二期国债发行工作有关事宜的通知  \n",
       "10648         中央法规司法解释         527  财政部办公厅关于2021年记账式附息七期国债发行工作有关事宜的通知  \n",
       "12846         中央法规司法解释         456  财政部办公厅关于2021年记账式附息十期国债发行工作有关事宜的通知  \n",
       "13903         中央法规司法解释         230  财政部办公厅关于2021年记账式附息三期国债发行工作有关事宜的通知  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5file.pdata.loc[[2519, 3672, 3709, 7970, 8140, 8506, 8881, 10648, 12846, 13903]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aee6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "17795\n",
    "String:\t内蒙古自治区2002年政府工作报告\n",
    "Index:\t26493\n",
    "String:\t内蒙古自治区2004年政府工作报告\n",
    "Index:\t34497\n",
    "String:\t内蒙古自治区2002年政府工作报告\n",
    "Index:\t41982\n",
    "String:\t内蒙古自治区2003年政府工作报告\n",
    "Index:\t43137\n",
    "String:\t内蒙古自治区2004年政府工作报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69596b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test8.txt', 'w', encoding='utf-8')\n",
    "repeat_count = 0\n",
    "hash_code_map_final_list = []\n",
    "repeat_2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a482ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hash_code_map: 100%|██████████| 4/4 [00:15<00:00,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish.\n",
      "CPU times: user 16.7 s, sys: 382 ms, total: 17.1 s\n",
      "Wall time: 17.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1. 先hash再辅助判断\n",
    "if h5file.type_id in [1, 4, 8, 9, 12, 14]:\n",
    "    hashTitleTri(h5file)\n",
    "# 2. doi先去重再hash\n",
    "elif type_id in [3, 5, 6, 7, 11]:\n",
    "    column_dic, empty_pdata_index, distinct_pdata_index = dedupWithColumn(h5file)\n",
    "    title_dic = hashTitleHex(h5file, empty_pdata_index, distinct_pdata_index)\n",
    "    mergeColumnAndTitle(id_set, column_dic, title_dic)\n",
    "    # r.hset(h5file.file_name + columns_list[str(type_id)][0], list(column_dic.keys())[0], json.dumps(column_dic)) \n",
    "# 直接hash:0,2,10,13\n",
    "else:\n",
    "    hashTitleTri(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c32009be",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.connection_pool.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b4e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179b3499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad803505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setNewIdSave(final_dic):\n",
    "    \"\"\"\n",
    "    将确定相同的数据的列表存为同一个new_id\n",
    "    \"\"\"\n",
    "    for k, index_list in final_dic.items():\n",
    "        new_id = worker.get_id()\n",
    "        for i in index_list:\n",
    "            r.rpush(new_id, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b82aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupWithColumn(h5file):\n",
    "    \"\"\"\n",
    "    修改self.pdata，删除column重复项，保留column为空项，供后面title_hash，此处未重置索引\n",
    "    返回三个变量：\n",
    "    column_dic：存储所有数据中column不为空的数据，格式为{'doi':[属于这个doi的所有id...]}\n",
    "    empty_pdata_index：column为空项的布尔索引\n",
    "    distinct_pdata_index：column为空的数据中，删除column重复项后剩下的数据的布尔索引\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # 以下是旧版本代码，将h5file.pdata复制了三份，内存翻倍\n",
    "    column_empty_pdata = h5file.pdata[h5file.pdata[column] == '']\n",
    "    column_not_empty_pdata = h5file.pdata[h5file.pdata[column] != '']\n",
    "    # 取一个别名(浅拷贝)\n",
    "    pdata = column_not_empty_pdata\n",
    "    # 存储所有数据中column不为空的数据，格式为{'doi':[属于这个doi的所有id...]}\n",
    "    column_dic = {value:df.id.tolist() for value,df in pdata.groupby(pdata[column]) if value != ''}\n",
    "    # 存储所有数据中column不为空的数据的column，格式为set\n",
    "    column_set = set(pdata[pdata[column] != ''][column].unique())\n",
    "    # 存储所有数据中column重复的数据（不含空值），格式为{'doi':[重复id...]}\n",
    "    dup_pdata = pdata[pdata.duplicated(subset=column,keep=False)]\n",
    "    dup_dic = {value:df.id.tolist() for value,df in dup_pdata.groupby(dup_pdata[column])}\n",
    "    # dup_dic = {value:df.id.tolist() for value,df in pdata.groupby(pdata[column]) if len(df) > 1}\n",
    "    # 修改self.pdata，删除column重复项，保留column为空项，供后面title_hash，此处重置索引\n",
    "    h5file.pdata = pd.concat([pdata.drop_duplicates(subset=column),column_empty_pdata],axis=0)\n",
    "    \"\"\"\n",
    "    column = columns_list[str(h5file.type_id)][0]\n",
    "    empty_pdata_index = (h5file.pdata[column] == '')\n",
    "    # 去重，保留第一次出现的数据，反转是为了使不重复的index为True\n",
    "    distinct_pdata_index = (h5file.pdata.duplicated(subset=column,keep='first') == False) \n",
    "    # 存储所有数据中column不为空的数据，格式为{'doi':[属于这个doi的所有id...]}\n",
    "    # column_dic = {value:df.id.tolist() for value,df in pdata.groupby(pdata[column]) if value != ''}\n",
    "    column_dic = {}\n",
    "    for value,df in tqdm(h5file.pdata.groupby(h5file.pdata[column]),desc='groupby'):\n",
    "        if value != '':\n",
    "            column_dic[value] = df.id.tolist()\n",
    "            break\n",
    "    \n",
    "    # 修改self.pdata，删除column重复项，保留column为空项，供后面title_hash，此处重置索引\n",
    "    # 谨慎修改self.pdata，因为post_proccess中可以会需要索引\n",
    "    # h5file.pdata = h5file.pdata[empty_pdata_index|distinct_pdata_index]\n",
    "    \n",
    "    return column_dic, empty_pdata_index, distinct_pdata_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993ce79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashTitleTri(h5file):\n",
    "    hash_code_map = {}\n",
    "    for index,row in h5file.pdata.iterrows():\n",
    "        # 获得hashcode\n",
    "        hash_code = hashString(row['title_code'])\n",
    "        # 将（hashcode， index）加入字典\n",
    "        if hash_code in hash_code_map:\n",
    "            hash_code_map[hash_code].append(index)\n",
    "        else:\n",
    "            hash_code_map[hash_code] = [index]\n",
    "            \n",
    "    # f = open('test.txt', 'w', encoding='utf-8')\n",
    "    # f = open('/Users/jas/Desktop/test.txt', 'w')\n",
    "\n",
    "    hash_code_map_final_list = []\n",
    "\n",
    "    for hash_code,index_list in tqdm(hash_code_map.items(),desc='hash_code_map'): \n",
    "        # if(len(index_list)>1):\n",
    "        # print('Hash_code:\\t{}'.format(hash_code))\n",
    "        # 对奇数位再哈希，两次相同则判断为同一字符 \n",
    "        reHashDicOdd = {}\n",
    "        for index in index_list:\n",
    "            # 1111_2222\n",
    "            hash_code_odd = str(hash_code) + '_' + str(hashStringOdd(h5file.pdata['title_code'][index]))\n",
    "            # hash_code_odd = hashStringOdd(pdata['title_code'][index])\n",
    "            if hash_code_odd in reHashDicOdd:\n",
    "                reHashDicOdd[hash_code_odd].append(index)\n",
    "            else:\n",
    "                reHashDicOdd[hash_code_odd] = [index]\n",
    "\n",
    "            # postPoccess(f, reHashDicOdd, pdata)\n",
    "\n",
    "            # \"\"\"\n",
    "            # 再采用间隔哈希(每三个)\n",
    "            # 再hash后max_bucket_size由600变为400，速度变为一半，召回个数减少约200个，约1%\n",
    "        for hash_code,index_list in reHashDicOdd.items(): \n",
    "            reHashDic3 = {}\n",
    "            for index in index_list:\n",
    "                # hash_code_3 = hashString3(pdata['title_code'][index])\n",
    "                # 1111_2222_3333\n",
    "                hash_code_3 = hash_code + '_' + str(hashString3(h5file.pdata['title_code'][index]))\n",
    "                if hash_code_3 in reHashDic3:\n",
    "                    reHashDic3[hash_code_3].append(index)\n",
    "                else:\n",
    "                    reHashDic3[hash_code_3] = [index]\n",
    "                # 精筛，注意这个代码要放在粗筛的最后一层，否则前面的筛选失效\n",
    "            postPoccess(h5file, reHashDic3)\n",
    "#             global postPoccess_count\n",
    "#             if postPoccess_count > 5:\n",
    "#                 assert 0\n",
    "#             else:\n",
    "#                 postPoccess_count += 1\n",
    "    f.close()    \n",
    "    print(\"Finish.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaa526ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postPoccess(h5file, hashDic):\n",
    "    \"\"\"\n",
    "    hash + 辅助判\n",
    "    断\n",
    "    对最终的hash表处理，找出相同的，写入文件\n",
    "    \"\"\" \n",
    "    # print(\"postPoccessing, length of hasdDic:{}\".format(len(hashDic)))\n",
    "    global max_bucket_size\n",
    "    global repeat_count\n",
    "    global hash_code_map_final_list\n",
    "    global repeat_2\n",
    "    \n",
    "    for hash_code,index_list in hashDic.items(): \n",
    "        r.hset(h5file.file_name + 'title_hash', hash_code, json.dumps({hash_code: h5file.pdata.loc[index_list]['id'].to_list()}))\n",
    "        length = len(index_list)\n",
    "        # 不需要用length删选了，因为如果length==1,那么以下的语句执行1次就会结束\n",
    "        # if length > 1:\n",
    "        max_bucket_size = max(max_bucket_size, length)\n",
    "        # 使用numpy加快处理速度(维度大于10000时提速显著)\n",
    "        visited = np.zeros([length+1], dtype = np.int)\n",
    "        hash_code_map_final = {}\n",
    "        for i in range(length):\n",
    "            \"\"\"\n",
    "            # visited[i]:\n",
    "            # 注意：如果该title已经并入其他title，则跳过（每个title只被匹配一次）\n",
    "            # 如果不跳过，可以增加召回率\n",
    "            # pdata['id_mark'][index_list[i]].endswith('a')):\n",
    "            # 使hash_code_map_final[i]的i标题不是通过alt复制出来的新行，三种情况：\n",
    "            # 1. 原标题（i）与alt（j）相似，alt被append到hash_code_map_final[原标题index]中\n",
    "            # 2. alt（i）与原标题（j）相似，被1中情况覆盖，跳过\n",
    "            # 3. alt（i）与alt（j）相似，一般alt对应的原标题也会相似，也跳过\n",
    "            \"\"\"\n",
    "            if visited[i] :\n",
    "                continue\n",
    "            # 初始化\n",
    "            hash_code_map_final[i] = [index_list[i]]\n",
    "            visited[i] = 1\n",
    "            for j in range(i+1, length):\n",
    "                if visited[j] != 1:\n",
    "                    # 提高效率\n",
    "                    temp_i = h5file.pdata['title_code'][index_list[i]]\n",
    "                    temp_j = h5file.pdata['title_code'][index_list[j]]\n",
    "                    if containChinese(temp_i) and len(temp_i) < 15:\n",
    "                        if fuzz.ratio(temp_i, temp_j) > 95:\n",
    "                            # 需要辅助判断\n",
    "                            if h5file.type_id in [1, 4, 8, 9, 12, 14]:\n",
    "                                column = columns_list[str(h5file.type_id)][0]\n",
    "                                if h5file.pdata[column][index_list[i]] == h5file.pdata[column][index_list[j]]:\n",
    "                                    hash_code_map_final[i].append(index_list[j])\n",
    "                                    visited[j] = 1\n",
    "                            else: # 不需要辅助判断\n",
    "                                hash_code_map_final[i].append(index_list[j])\n",
    "                                visited[j] = 1\n",
    "                    else:\n",
    "                        if fuzz.ratio(temp_i, temp_j) > 85:\n",
    "                            # 需要辅助判断\n",
    "                            if h5file.type_id in [1, 4, 8, 9, 12, 14]:\n",
    "                                column = columns_list[str(h5file.type_id)][0]\n",
    "                                if h5file.pdata[column][index_list[i]] == h5file.pdata[column][index_list[j]]:\n",
    "                                    hash_code_map_final[i].append(index_list[j])\n",
    "                                    visited[j] = 1\n",
    "                            else: # 不需要辅助判断\n",
    "                                hash_code_map_final[i].append(index_list[j])\n",
    "                                visited[j] = 1\n",
    "                    \"\"\"\n",
    "                    这样会出现这种情况：\n",
    "                    有一条记录：title：中文1（index：2），alt：英文a（index：4），分别与另外两条记录相似\n",
    "                    title：中文2（index：1） 相似于 中文1\n",
    "                    title：英文b（index：3） 相似于 英文a\n",
    "                    处理后他们被归入两个字典：\n",
    "                    {1:[1, 2]}\n",
    "                    {3:[3, 4]}\n",
    "                    他们都属于相似的标题，需要在最后，使用并查集操作使他们归并到同一个集合\n",
    "                    \"\"\"\n",
    "            \"\"\"\n",
    "            \n",
    "            # redis for j循环结束\n",
    "            # 如果length==1那么不会进入j循环，直接存redis\n",
    "            new_id_for_key = worker.get_id()\n",
    "            # 重复列表中的index索引id\n",
    "            old_dup_id_list = h5file.pdata.loc[hash_code_map_final[i]]['id'].to_list()\n",
    "            # print(new_id_for_key,':',old_dup_id_list)\n",
    "\n",
    "            for old_id in old_dup_id_list:\n",
    "                r.rpush(new_id_for_key, old_id)   # {new_id: [dup_old_id, , ]}\n",
    "                r.set(old_id, new_id_for_key)   # {old_id : new_id}\n",
    "            \"\"\"\n",
    "\n",
    "        hash_code_map_final_list.append(hash_code_map_final)\n",
    "        for hash_code,index_list in hash_code_map_final.items():  # hash_code 为index\n",
    "            if (len(index_list)) > 1:\n",
    "                # redis\n",
    "\n",
    "                repeat_count += (len(index_list)-1)\n",
    "                if (len(index_list)) == 2:\n",
    "                    repeat_2 += 1  \n",
    "                f.writelines(['*********************************************Same ReHash*********************************************\\n'])\n",
    "                for index in index_list:\n",
    "                    # repeat_count += 1\n",
    "                    f.writelines(['Index:\\t', str(index), '\\n', 'String:\\t', h5file.pdata['title'][index], '\\n'])                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfaa59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_symbol(s):\n",
    "    # return s.upper().translate(punc_table)\n",
    "    tmp_s = s.translate(punc_table).upper()\n",
    "    \n",
    "    re.sub(r'')\n",
    "    if tmp_s == '':\n",
    "        tmp_s = '[untitled]' \n",
    "    return tmp_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0d935c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "变量 = '第一期 第九3批'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d2ecaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'[\\(（\\<《\\[【\\{「]第*[\\u96f6\\u3007\\u4e00\\u4e8c\\u4e09\\u56db\\u4e94\\u516d\\u4e03\\u516b\\u4e5d\\u5341\\d]{1,5}[\\u4e00-\\u9fa5]*[\\)）\\>》\\]】\\}」]')\n",
    "pattern = re.compile(r'第[\\u96f6\\u3007\\u4e00\\u4e8c\\u4e09\\u56db\\u4e94\\u516d\\u4e03\\u516b\\u4e5d\\u5341\\d]{1,5}[次|批|期|号|卷]')\n",
    "result = re.findall(pattern,变量)\n",
    "for token in result:\n",
    "    变量 = 变量.replace(token,token*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ed222a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一期第一期第一期第一期第一期第一期第一期第一期第一期第一期 第九3批第九3批第九3批第九3批第九3批第九3批第九3批第九3批第九3批第九3批\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "中国金融期货交易所关于发布国债期货合约TF2112、T2112和TS2112可交割国债的通知\n",
    "Index:\t11571\n",
    "String:\t中国金融期货交易所关于发布国债期货合约TF2203、T2203和TS2203可交割国债的通知"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d30380dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio('中国金融期货交易所关于发布国债期货合约TF2112、T2112和TS2112可交割国债的通知', '中国金融期货交易所关于发布国债期货合约TF2203、T2203和TS2203可交割国债的通知')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa78a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata4[pd.concat([(pdata3[0] == 1),(pdata3[0] == 1)],axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b944b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3a4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata4 = pd.concat([pdata3,pdata3],axis=0)\n",
    "pdata4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be9ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata3 = pd.DataFrame([[1,1],[2,2],[1,1],[1,1],[1,''],[1,'']])\n",
    "pdata3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata3[1].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5512de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_dup_index = pdata3[1].duplicated() == False\n",
    "not_dup_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635507e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_index = pdata3[1] == ''\n",
    "empty_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd50cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata3[not_dup_index|empty_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_dup_index = pdata3[1].duplicated() == False\n",
    "empty_index = pdata3[1] == ''\n",
    "pdata3[not_dup_index|empty_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22b774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9048716",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata3.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata3.drop_duplicates(subset=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c052ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata3.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a368d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b332d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pdata2 = pdata.drop_duplicates(subset='identifier_standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355570bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata[pdata.duplicated(subset='identifier_standard')].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pdata2.id == '207200692096').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pdata.id == '207200692096').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdata2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdata[pdata.duplicated(subset='identifier_standard',keep=False)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c6073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df.identifier_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "{j[0]:j[1].id.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0005a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20e177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796927ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34978d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aeaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15300e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = h5file.pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e33e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489cf2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taskDispatch(type_id, pdata):\n",
    "    \"\"\"\n",
    "    1. 先hash再辅助判断\n",
    "    2. doi先去重再hash\n",
    "    3. 直接hash\n",
    "    \"\"\"\n",
    "    if type_id in [1, 4, 8, 9, 12, 14]:\n",
    "        hash_and_judge(h5file)\n",
    "    elif type_id in [3, 5, 6, 7, 11]:\n",
    "        dedup_and_hashe(h5file)\n",
    "    # others 2 10 13 0\n",
    "    else:\n",
    "        hash_only(h5file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4958279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a33b0b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'20212310947'\n"
     ]
    }
   ],
   "source": [
    "for i in r.keys('2021*'):\n",
    "    print (i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7116ce30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4710943"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.keys('[0-9]'*19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "633f87ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio('', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d5cf6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>creator</th>\n",
       "      <th>creator_institution</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20468132472</td>\n",
       "      <td>我国生鲜乳价格风险测度与管理研究</td>\n",
       "      <td>ZH</td>\n",
       "      <td>刘秉华</td>\n",
       "      <td>河北农业大学</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20468466751</td>\n",
       "      <td>冀东地区土壤重金属元素基线值确定</td>\n",
       "      <td>ZH</td>\n",
       "      <td>焦建</td>\n",
       "      <td>河北地质大学</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20468563375</td>\n",
       "      <td>氧化石墨烯的飞秒激光结构化处理及其浸润性调控</td>\n",
       "      <td>ZH</td>\n",
       "      <td>王飞跃</td>\n",
       "      <td>中国科学院大学(中国科学院长春光学精密机械与物理研究所)</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20468594821</td>\n",
       "      <td>铝合金的机器人气囊柔性抛光关键技术研究</td>\n",
       "      <td>ZH</td>\n",
       "      <td>邱磊</td>\n",
       "      <td>厦门理工学院</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20468595217</td>\n",
       "      <td>智慧校园APP交互界面设计实践与研究 ——以“We辽师”为例</td>\n",
       "      <td>ZH</td>\n",
       "      <td>薛天</td>\n",
       "      <td>辽宁师范大学</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20468594579</td>\n",
       "      <td>建安士风与公宴诗赋</td>\n",
       "      <td>ZH</td>\n",
       "      <td>蒋聪慧</td>\n",
       "      <td>辽宁师范大学</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20468595190</td>\n",
       "      <td>北方旱作春玉米水分生产力时空变化的模拟研究</td>\n",
       "      <td>ZH</td>\n",
       "      <td>李威</td>\n",
       "      <td>中国农业科学院</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20467257089</td>\n",
       "      <td>Improving student reading achievement through ...</td>\n",
       "      <td>EN</td>\n",
       "      <td>Johnson, Shawn M.</td>\n",
       "      <td>University of Delaware</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20467372234</td>\n",
       "      <td>CYRI-A is recruited to macropinocytic cups and...</td>\n",
       "      <td>EN</td>\n",
       "      <td>Le, Hoang Anh</td>\n",
       "      <td>University of Glasgow</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20467695164</td>\n",
       "      <td>Generative adversarial models for privacy-pres...</td>\n",
       "      <td>EN</td>\n",
       "      <td>Vasterd, M.F.J.</td>\n",
       "      <td>University of Twente</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                              title language  \\\n",
       "1   20468132472                                   我国生鲜乳价格风险测度与管理研究       ZH   \n",
       "2   20468466751                                   冀东地区土壤重金属元素基线值确定       ZH   \n",
       "3   20468563375                             氧化石墨烯的飞秒激光结构化处理及其浸润性调控       ZH   \n",
       "4   20468594821                                铝合金的机器人气囊柔性抛光关键技术研究       ZH   \n",
       "5   20468595217                     智慧校园APP交互界面设计实践与研究 ——以“We辽师”为例       ZH   \n",
       "..          ...                                                ...      ...   \n",
       "5   20468594579                                          建安士风与公宴诗赋       ZH   \n",
       "6   20468595190                              北方旱作春玉米水分生产力时空变化的模拟研究       ZH   \n",
       "0   20467257089  Improving student reading achievement through ...       EN   \n",
       "1   20467372234  CYRI-A is recruited to macropinocytic cups and...       EN   \n",
       "2   20467695164  Generative adversarial models for privacy-pres...       EN   \n",
       "\n",
       "              creator           creator_institution source_file  \n",
       "1                 刘秉华                        河北农业大学         111  \n",
       "2                  焦建                        河北地质大学         111  \n",
       "3                 王飞跃  中国科学院大学(中国科学院长春光学精密机械与物理研究所)         111  \n",
       "4                  邱磊                        厦门理工学院         111  \n",
       "5                  薛天                        辽宁师范大学         111  \n",
       "..                ...                           ...         ...  \n",
       "5                 蒋聪慧                        辽宁师范大学         391  \n",
       "6                  李威                       中国农业科学院         391  \n",
       "0   Johnson, Shawn M.        University of Delaware         772  \n",
       "1       Le, Hoang Anh         University of Glasgow         772  \n",
       "2     Vasterd, M.F.J.          University of Twente         772  \n",
       "\n",
       "[99 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_hdf(path_or_buf='./data/4_2021.h5', start=1, stop=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af2010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054ce2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d2a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1336bd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef1d032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb576d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9329f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dedd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in dic1.items():\n",
    "    print('index:',i)\n",
    "    print('dupl:',j)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.id[pdata['identifier_pisbn'] == '9787520172578'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf4cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata['id'][pdata['identifier_pisbn'] == '9787520172578'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.loc[pdata['identifier_pisbn'] == '9787520172578']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbf958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c7a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16585964",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_p_count = pdata['identifier_pisbn'].value_counts()\n",
    "i_p_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cd9ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_p_count[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in i_p_count[i_p_count > 1].iteritems():\n",
    "    print(i,j)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5601f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d81902",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_p_count[i_p_count > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5eeb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77803353",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pdata.language == 'ZH').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pdata.language == 'ZH').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7214f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.loc[pdata.language == 'ZH', 'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac39d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535fcb0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9682b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata1 = pd.read_hdf('data/3_2021.h5')\n",
    "pdata1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pdata1.identifier_doi.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b38ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata1.identifier_doi.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9f7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata1[pdata1.identifier_doi == '10.1016/j.scitotenv.2020.141974']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4169226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pdata1[pdata1.language == 'EN'].identifier_doi.value_counts()>2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293f39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata1['identifier_doi'][100:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f823c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdata1.identifier_doi.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61a0d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
