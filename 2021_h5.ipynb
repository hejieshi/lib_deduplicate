{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a4bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbfbe75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d83ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from fastavro import reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# 生成ID\n",
    "from generate_id import IdWorker\n",
    "import datetime\n",
    "CURRENT_YEAR = datetime.datetime.now().year\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '64'\n",
    "\n",
    "# 设置logging\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO,format = '%(asctime)s %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger()\n",
    "f_handler = logging.FileHandler('error'+datetime.datetime.now().strftime('%Y_%m_%d')+'.log', mode='w')\n",
    "f_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s: %(message)s'))\n",
    "logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01ed3bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ori'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dbe14fd3227e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# 生成ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIdWorker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ori'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.avro'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mweipu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAvro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ori/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ori'"
     ]
    }
   ],
   "source": [
    "class Avro():\n",
    "    r\"\"\"\n",
    "    按行读取 avro\n",
    "    智图的 avro 里面 key/value 均为 str\n",
    "    数值类字段值在 avro 里面也已 str 存放\n",
    "    \"\"\"\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        \"\"\"\n",
    "        self.columns_list = {'0':[],\\\n",
    "                             '1':['identifier_pisbn'],\\\n",
    "                             '2':['identifier_pisbn'],\\\n",
    "                             '3':['identifier_doi'],\\\n",
    "                             '4':['creator', 'creator_institution'],\\\n",
    "                             '5':['identifier_standard'],\\\n",
    "                             '6':['identifier_doi'],\\\n",
    "                             '7':['identifier_standard'],\\\n",
    "                             '8':['provider_subject'],\\\n",
    "                             '9':['creator_institution'],\\\n",
    "                             '10':[],\\\n",
    "                             '11':['identifier_doi'],\\\n",
    "                             '12':['source'],\\\n",
    "                             '13':[],\\\n",
    "                             '14':['date_created']}\n",
    "        string_size_dic = {'0':{'title':255,'language':2},\\\n",
    "                             '1':{'title':255,'language':2,'identifier_pisbn':20},\\\n",
    "                             '2':{'title':255,'language':2,'identifier_pisbn':20},\\\n",
    "                             '3':{'title':255,'language':2,'identifier_doi':70},\\\n",
    "                             '4':{'title':255,'language':2,'creator':100,'creator_institution':100},\\\n",
    "                             '5':{'title':255,'language':2,'identifier_standard':100},\\\n",
    "                             '6':{'title':255,'language':2,'identifier_doi':70},\\\n",
    "                             '7':{'title':255,'language':2,'identifier_standard':100},\\\n",
    "                             '8':{'title':255,'language':2,'provider_subject':100},\\\n",
    "                             '9':{'title':255,'language':2,'creator_institution':100},\\\n",
    "                             '10':{'title':255,'language':2},\\\n",
    "                             '11':{'title':255,'language':2,'identifier_doi':70},\\\n",
    "                             '12':{'title':255,'language':2,'source':100},\\\n",
    "                             '13':{'title':255,'language':2},\\\n",
    "                             '14':{'title':255,'language':2}}\n",
    "        \"\"\"\n",
    "        self.columns_list = {'0':[],\\\n",
    "                             '1':['identifier_pisbn'],\\\n",
    "                             '2':['identifier_pisbn'],\\\n",
    "                             '3':['identifier_doi'],\\\n",
    "                             '4':['creator', 'creator_institution'],\\\n",
    "                             '5':['identifier_standard'],\\\n",
    "                             '6':['identifier_doi'],\\\n",
    "                             '7':['identifier_standard'],\\\n",
    "                             '8':['provider_subject'],\\\n",
    "                             '9':['creator_institution'],\\\n",
    "                             '10':[],\\\n",
    "                             '11':['identifier_doi'],\\\n",
    "                             '12':['source'],\\\n",
    "                             '13':[],\\\n",
    "                             '14':['date_created']}\n",
    "        self.string_size_dic = {'0':{'title':400,'language':2},\\\n",
    "                             '1':{'title':400,'language':2,'identifier_pisbn':50},\\\n",
    "                             '2':{'title':400,'language':2,'identifier_pisbn':50},\\\n",
    "                             '3':{'title':400,'language':2,'identifier_doi':50},\\\n",
    "                             '4':{'title':400,'language':2,'creator':50,'creator_institution':80},\\\n",
    "                             '5':{'title':400,'language':2,'identifier_standard':50},\\\n",
    "                             '6':{'title':400,'language':2,'identifier_doi':50},\\\n",
    "                             '7':{'title':400,'language':2,'identifier_standard':50},\\\n",
    "                             '8':{'title':400,'language':2,'provider_subject':50},\\\n",
    "                             '9':{'title':400,'language':2,'creator_institution':80},\\\n",
    "                             '10':{'title':400,'language':2},\\\n",
    "                             '11':{'title':400,'language':2,'identifier_doi':50},\\\n",
    "                             '12':{'title':400,'language':2,'source':150},\\\n",
    "                             '13':{'title':400,'language':2},\\\n",
    "                             '14':{'title':400,'language':2}}\n",
    "        self.source_file_dtype = pd.api.types.CategoricalDtype(categories=list(range(1000)))\n",
    "        # ''空字符串不是np.nan\n",
    "        self.language_dtype = pd.api.types.CategoricalDtype(categories=['ZH','EN','JA','DE','SP','ID',\\\n",
    "                                                                        'FR','MS','HU','ES','PT','IT',\\\n",
    "                                                                        'PL','SR','RO','HR','SW','HI',\\\n",
    "                                                                        'RU','NL','AR','EL','FA','LT',\\\n",
    "                                                                        'UN','SL','TR','NO','CS','KO',\\\n",
    "                                                                        'SH','SK','DA','BS','SV','UK',\\\n",
    "                                                                        'IS','ET','CA','BG','AF','FI',\\\n",
    "                                                                        'HE','MO','EO','EU','LA','TH',\\\n",
    "                                                                        'LV','MK','CH',''])\n",
    "        \n",
    "  \n",
    "    \n",
    "    def ReadAvro(self):\n",
    "        with open(self.file, 'rb') as fo, open('text.txt','w') as f_w:\n",
    "            for record in tqdm(reader(fo), desc=\"ReadAvro\"):\n",
    "                # f_w.writelines(json.dumps(record, ensure_ascii=False))\n",
    "                # f_w.write('\\n')\n",
    "                if record['value']['title'] == '[untitled]':\n",
    "                    print(record)\n",
    "                    time.sleep(1)\n",
    "\n",
    "\n",
    "    def ExtractDic(self, record_dic, type_):\n",
    "        new_dic = {}\n",
    "        # id\n",
    "        new_dic['id'] = record_dic['id']\n",
    "        # title\n",
    "        if 'title' not in record_dic:\n",
    "            # title = '[untitled]'代表元数据中title缺失\n",
    "            new_dic['title'] = '[untitled]'\n",
    "        else:\n",
    "            new_dic['title'] = record_dic['title'][:200]\n",
    "        \"\"\"\n",
    "        # 由于枚举类型必须提请规定好取值范围，所以title_alternative用枚举类型存储不太合适\n",
    "        # 用object存储则太费空间，所以本次暂时跳过\n",
    "        # title_alternative\n",
    "        if type_ in ['3','6']:\n",
    "            if 'title_alternative' not in record_dic:\n",
    "                # title_alternative = ''代表元数据中title缺失\n",
    "                new_dic['title_alternative'] = ''\n",
    "            else:\n",
    "                new_dic['title_alternative'] = record_dic['title_alternative'][:200]\n",
    "        \"\"\"\n",
    "        # 11报纸没有language，为了数据统一，给它加上language\n",
    "        if 'language' not in record_dic:\n",
    "            # 默认zh\n",
    "            new_dic['language'] = 'ZH'\n",
    "        else:\n",
    "            new_dic['language'] = record_dic['language'][:2]\n",
    "        # 其他字段\n",
    "        for column in self.columns_list[type_]:\n",
    "            if column not in record_dic:\n",
    "                # 其他字段空的时候用空字符代替\n",
    "                new_dic[column] = ''\n",
    "            else:\n",
    "                new_dic[column] = record_dic[column][:50]\n",
    "        # 记录来源文件\n",
    "        # new_dic['source_file'] = self.file[-18:]\n",
    "        new_dic['source_file'] = int(re.search(r'\\d+',self.file).group())\n",
    "        return new_dic\n",
    "            \n",
    "    \n",
    "    def AvroToHdf5(self):\n",
    "        try:\n",
    "            logger.info(\"Poccessing File: {}\".format(self.file))    \n",
    "            # 建立一个空的“总表”avro_dic为{'type':[特定type、date的元数据]}\n",
    "            # 先按照type分类\n",
    "            avro_dic = {}\n",
    "            # type_id=0~14，0代表元数据中类型缺失\n",
    "            for type_id in range(15):\n",
    "                avro_dic[str(type_id)] = []\n",
    "                \n",
    "            # 读数据\n",
    "            count = 0\n",
    "            with open(self.file, 'rb') as fo:\n",
    "                for line_id, record in tqdm(enumerate(reader(fo)), desc='Reading Avro'):\n",
    "                    count += 1\n",
    "                    # 只要2021的数据\n",
    "                    if 'date' not in record['value']:\n",
    "                        continue\n",
    "                    elif record['value']['date'] != '2021':\n",
    "                        continue\n",
    "                    # 获取type  \n",
    "                    if 'type' not in record['value']:\n",
    "                        # type = '0'代表元数据中date缺失\n",
    "                        type_ = '0'\n",
    "                    else:\n",
    "                        type_ = record['value']['type']\n",
    "                    # 提取需要的字段存入tmp_dic   \n",
    "                    tmp_dic = self.ExtractDic(record['value'], type_) \n",
    "                    # 存入“总表”\n",
    "                    avro_dic[type_].append(tmp_dic)       \n",
    "\n",
    "            # 存入HDF5文件，key为date年份，value为对应的字典列表\n",
    "            for type_id, record in tqdm(avro_dic.items(), desc='Storing'):\n",
    "                file_name = './data/' + type_id + '_' + '2021' + '.h5'\n",
    "                if record != []:\n",
    "                    tmp_data = pd.DataFrame(record)\n",
    "                    # 转化为枚举类别category\n",
    "                    # 枚举类别在to_hdf(append=True)时要保证取值范围完全相同\n",
    "                    tmp_data[['source_file']] = tmp_data[['source_file']].astype(self.source_file_dtype)\n",
    "                    # 报纸没有language，但是前面已经加上了\n",
    "                    tmp_data[['language']] = tmp_data[['language']].astype(self.language_dtype)\n",
    "                    \"\"\"\n",
    "                    # 包含titile_alternative的类型\n",
    "                    if type_id in ['3','6']:\n",
    "                        tmp_data[['titile_alternative']] = tmp_data[['titile_alternative']].astype('category')\n",
    "                    # 包含creator_institution的类型\n",
    "                    elif type_id in ['4','9']:\n",
    "                        tmp_data[['creator_institution']] = tmp_data[['creator_institution']].astype('category')\n",
    "                    # 法律法规\n",
    "                    elif type_id == '8':\n",
    "                        tmp_data[['provider_subject']] = tmp_data[['provider_subject']].astype('category')\n",
    "                    \"\"\"\n",
    "                    # 资讯\n",
    "                    if type_id == '14':\n",
    "                        try:\n",
    "                            tmp_data[['date_created']] = tmp_data[['date_created']].astype('datetime64')\n",
    "                        except:\n",
    "                            logger.error(\"{} IN POCCESSING {}! FOUND TYPE14 DATE_CREATED ERROR! SKIP!\".format(e, self.file))\n",
    "                            continue\n",
    "                    # 使用'table'模式时，DataFrame不能为空否则报错，而使用‘fixed’时可以为空\n",
    "                    # 原数据title最长有2千多，一般超过255的title是无意义的，设置为255\n",
    "                    # 注意min_itemsize是字节，前面截断是按字符长度\n",
    "                    # 如同样是len为10的字符串，存储时全部英文字母has a limit of [10]\n",
    "                    # 全部中文has a limit of [30]\n",
    "                    # Map column names to minimum string sizes for columns.\n",
    "                    pd.DataFrame(tmp_data).to_hdf(file_name, 'obj', format='table', \\\n",
    "                                                  append=True, min_itemsize=self.string_size_dic[type_id])\n",
    "\n",
    "            logger.info(\"Length of File {} : {}.\".format(self.file, count))\n",
    "        except BaseException as e:\n",
    "            logger.error(\"{} IN POCCESSING {}! SKIP!\".format(e, self.file))\n",
    "            \n",
    "        \n",
    "    def GetYear(self, date:str):\n",
    "        if date == '':\n",
    "            return \"unknown\"\n",
    "        year = int(date)\n",
    "        if year < 1500 or year > CURRENT_YEAR:\n",
    "            return \"unknown\"\n",
    "        elif year >= 1500 and year < 1980:\n",
    "            return 'old'\n",
    "        elif year >= 1980 and year <= CURRENT_YEAR:\n",
    "            return date\n",
    "        else:\n",
    "            return \"unknown\"       \n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    if os.path.exists('./data'):\n",
    "        os.system('rm -rf data')\n",
    "    os.makedirs('./data')\n",
    "    \n",
    "    # 生成ID\n",
    "    worker = IdWorker(1,2)\n",
    "    for file in os.listdir('./ori'):\n",
    "        if file.find('.avro') != -1:\n",
    "            weipu = Avro(os.path.join(os.getcwd(), 'ori/'+file))\n",
    "            weipu.AvroToHdf5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50be9f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef763413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ccdef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e846a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root,dirs,files in os.walk('./'):\n",
    "#     for file in files:\n",
    "#         #获取文件所属目录\n",
    "#         print(root)\n",
    "#         #获取文件路径\n",
    "#         print(os.path.join(root,file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad20dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bab04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "921ad4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cade6fb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File ./data/3_2021.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-efcd1373e5fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/3_2021.h5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'obj'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/iec/lib/python3.6/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File ./data/3_2021.h5 does not exist"
     ]
    }
   ],
   "source": [
    "pdata = pd.read_hdf('./data/3_2021.h5','obj','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6b853b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-660116212eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pdata' is not defined"
     ]
    }
   ],
   "source": [
    "pdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94525d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47cdc36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9efc2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dtype = pd.api.types.CategoricalDtype(categories=['1','2',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame([{'a':'20210911','b':'20210912'},{'a':'2021933','b':'20210914'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aff721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04432c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['a'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fc9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1[list('a')] = data1[list('a')].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9185fc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4f4bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_hdf('test.h5','obj',format='table',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata = pd.read_hdf('test.h5','obj','r')\n",
    "pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9867cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4afb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('test.h5','obj',format='table',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b52698",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame([{'a':2,'b':2},{'a':2,'b':2}])\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[list('a')] = data2[list('a')].astype(cat_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbaac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_union = pd.concat([data1,data2])\n",
    "data_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_union.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "for i in range(100000):\n",
    "    tmp_dic = {'object':'object'+str(i), 'category':'这是一句中文这是一句中文这是一句中文这是一句中文这是一'*20 if i == 2 else ''}\n",
    "    test_list.append(tmp_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7361885",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b89a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('00默认min_itemsize只有一行数据的情况.h5','obj',\\\n",
    "             format='table',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa3abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "for i in range(100000):\n",
    "    tmp_dic = {'object':'object'+str(i), 'category':'alll_this_line_is_not_empty'*100}\n",
    "    test_list.append(tmp_dic)\n",
    "\n",
    "data2 = pd.DataFrame(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2214b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('00默认min_itemsize有全部数据(含1个中文len不变)的情况.h5','obj',\\\n",
    "             format='table',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b684f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42696338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0baf46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof('中lll_this_line_is_not_empty'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('00min设置为270有全部数据(全是中文len不变)的情况.h5','obj',\\\n",
    "             format='table',append=True,min_itemsize=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[['category']] = data2[['category']].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708435da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('00默认min_itemsize只有一行全部数据(category转换枚举类型)的情况.h5','obj',\\\n",
    "             format='table',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672150e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[data2.columns] = data2[data2.columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2616a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('00默认min_itemsize只有一行全部数据(全部转换枚举类型)的情况.h5','obj',\\\n",
    "             format='table',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_hdf('00min设置为270有全部数据(category转换枚举类型)的情况.h5','obj',\\\n",
    "             format='table',append=True,min_itemsize=270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ff3de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
